{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:  (404290, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import training data\n",
    "trainPath = '.\\Data\\\\train.csv'\n",
    "train = pd.read_csv(trainPath)\n",
    "print('training shape: ', train.shape)\n",
    "display(train.head())\n",
    "\n",
    "# test data doesn't have labels so we can't use it to evaluate model accuracy\n",
    "# instead, i'll train-test-split the \"train.csv\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Set Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    255027\n",
      "1    149263\n",
      "Name: is_duplicate, dtype: int64\n",
      "\n",
      "0    63.080215\n",
      "1    36.919785\n",
      "Name: is_duplicate, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of classes\n",
    "print(train[\"is_duplicate\"].value_counts()); print() # count\n",
    "print((train[\"is_duplicate\"].value_counts()/train[\"is_duplicate\"].count())*100) # percent\n",
    "\n",
    "# plot \n",
    "train[\"is_duplicate\"].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of null values: \n",
      " id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       0\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop nan values\n",
    "train = train.dropna()\n",
    "\n",
    "# number of nan values after cleaning\n",
    "print('number of null values: \\n', train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of duplicate values\n",
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling Due To Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before undersampling:\n",
      "Counter({0: 255024, 1: 149263})\n",
      "\n",
      "after undersampling:\n",
      "Counter({0: 149263, 1: 149263})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random undersampling to fix class imbalance\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# summarize class distribution\n",
    "print('before undersampling:')\n",
    "print(Counter(train['is_duplicate'])); print()\n",
    "\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "# X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "train, _ = undersample.fit_resample(train, train['is_duplicate'])\n",
    "\n",
    "# summarize class distribution\n",
    "print('after undersampling:')\n",
    "print(Counter(train['is_duplicate']))\n",
    "\n",
    "# plot\n",
    "train['is_duplicate'].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sampling (label counts):\n",
      "Counter({1: 50064, 0: 49936})\n",
      "\n",
      "after sampling (label percentages):\n",
      "1    50.064\n",
      "0    49.936\n",
      "Name: is_duplicate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# downsample for compute purposes\n",
    "train = train.sample(100000, random_state=42)\n",
    "\n",
    "print('after sampling (label counts):')\n",
    "print(Counter(train['is_duplicate'])); print()\n",
    "print('after sampling (label percentages):')\n",
    "print((train[\"is_duplicate\"].value_counts()/train[\"is_duplicate\"].count())*100) # percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Question Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = set(nltk.corpus.words.words())\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_question(question):\n",
    "    \n",
    "    # lowercase\n",
    "    question = question.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    question = \"\".join([char for char in question if char not in string.punctuation])\n",
    "    \n",
    "    # remove non-english words\n",
    "    question = \" \".join(word for word in re.split('\\W+', question) if word in eng_words)\n",
    "    \n",
    "    # remove stopwords\n",
    "    question = \" \".join([word for word in re.split('\\W+', question) if word not in stopword])\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ta1031742\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97122, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>364720</td>\n",
       "      <td>494790</td>\n",
       "      <td>484904</td>\n",
       "      <td>god hate made</td>\n",
       "      <td>god homosexuality make possible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231577</th>\n",
       "      <td>221233</td>\n",
       "      <td>328525</td>\n",
       "      <td>328526</td>\n",
       "      <td>photon retina eye</td>\n",
       "      <td>photon go retina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109421</th>\n",
       "      <td>121761</td>\n",
       "      <td>197246</td>\n",
       "      <td>197247</td>\n",
       "      <td>legitimate beating best</td>\n",
       "      <td>history star</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47536</th>\n",
       "      <td>249661</td>\n",
       "      <td>363349</td>\n",
       "      <td>195254</td>\n",
       "      <td>new know going first day stage</td>\n",
       "      <td>new know going first day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228283</th>\n",
       "      <td>212447</td>\n",
       "      <td>9163</td>\n",
       "      <td>46561</td>\n",
       "      <td>best coaching</td>\n",
       "      <td>coaching institute best location want score</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                       question1  \\\n",
       "284788  364720  494790  484904                   god hate made   \n",
       "231577  221233  328525  328526               photon retina eye   \n",
       "109421  121761  197246  197247         legitimate beating best   \n",
       "47536   249661  363349  195254  new know going first day stage   \n",
       "228283  212447    9163   46561                   best coaching   \n",
       "\n",
       "                                          question2  is_duplicate  \n",
       "284788              god homosexuality make possible             1  \n",
       "231577                             photon go retina             1  \n",
       "109421                                 history star             0  \n",
       "47536                      new know going first day             0  \n",
       "228283  coaching institute best location want score             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean question1 and update dataframe\n",
    "for idx, question in enumerate(train['question1']):\n",
    "    train['question1'].iloc[idx] = clean_question(question)\n",
    "    \n",
    "# clean question2 and update dataframe\n",
    "for idx, question in enumerate(train['question2']):\n",
    "    train['question2'].iloc[idx] = clean_question(question)\n",
    "    \n",
    "# drop rows with empty questions after cleaning\n",
    "train['question1'].replace('', np.nan, inplace=True)\n",
    "train['question2'].replace('', np.nan, inplace=True)\n",
    "train = train.dropna(how='any')\n",
    "\n",
    "print(train.shape) # will be slightly less than 100k\n",
    "train.head() # questions should be cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (77697, 2)\n",
      "y_train shape:  (77697,)\n",
      "X_test shape:  (19425, 2)\n",
      "y_test shape:  (19425,)\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Now go to Count/TFIDF vectorization OR GloVe word embeddings.\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[['question1', 'question2']], train['is_duplicate'], test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape); print()\n",
    "\n",
    "print('----------------------------------------------------------------')\n",
    "print('Now go to Count/TFIDF vectorization OR GloVe word embeddings.')\n",
    "print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count and TFIDF Vectorization - DONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat questions for vectorization\n",
    "train_questions = list(X_train['question1']) + list(X_train['question2'])\n",
    "test_questions = list(X_test['question1']) + list(X_test['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 shape:  (77697, 3000)\n",
      "q2 shape:  (77697, 3000)\n"
     ]
    }
   ],
   "source": [
    "# initialize vectorizer\n",
    "# vec = TfidfVectorizer(max_features=3000)\n",
    "vec = CountVectorizer(max_features=3000)\n",
    "\n",
    "# fit vectorizer of training questions\n",
    "vec = vec.fit(train_questions)\n",
    "\n",
    "# transform training and test questions\n",
    "train_questions_vectorized = vec.transform(train_questions)\n",
    "test_questions_vectorized = vec.transform(test_questions)\n",
    "\n",
    "# split\n",
    "train_q1, train_q2 = np.vsplit(train_questions_vectorized.toarray(),2)\n",
    "test_q1, test_q2 = np.vsplit(test_questions_vectorized.toarray(),2)\n",
    "\n",
    "# concatenate along column axis\n",
    "train_all_qs = np.concatenate((train_q1, train_q2), axis=1)\n",
    "test_all_qs = np.concatenate((test_q1, test_q2), axis=1)\n",
    "\n",
    "# turn to dataframe\n",
    "X_train = pd.DataFrame(train_all_qs)\n",
    "X_test = pd.DataFrame(test_all_qs)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data - change name of file!!!\n",
    "with open('countvec.pickle', 'wb') as handle:\n",
    "    pickle.dump([X_train, X_test, y_train, y_test], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Word Embeddings - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary length:  15056\n"
     ]
    }
   ],
   "source": [
    "# proprocess questions\n",
    "train_questions = list(X_train['question1']) + list(X_train['question2'])\n",
    "test_questions = list(X_test['question1']) + list(X_test['question2'])\n",
    "\n",
    "# prepare tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_questions)\n",
    "\n",
    "# create the word_index dictionary \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# get the vocabulary\n",
    "vocabulary = list(word_index.keys())\n",
    "print('vocabulary length: ', len(vocabulary))\n",
    "\n",
    "# convert questions into sequences (integer encoding)\n",
    "sequences_train = tokenizer.texts_to_sequences(train_questions)\n",
    "sequences_test = tokenizer.texts_to_sequences(test_questions)\n",
    "\n",
    "# pad sequences so all have same length\n",
    "max_len = 50\n",
    "sequences_train = pad_sequences(sequences_train, maxlen=max_len, padding='post')\n",
    "sequences_test = pad_sequences(sequences_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (77697, 100)\n",
      "y_train shape:  (77697,)\n",
      "X_test shape:  (19425, 100)\n",
      "y_test shape:  (19425,)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "train_q1, train_q2 = np.vsplit(sequences_train, 2)\n",
    "test_q1, test_q2 = np.vsplit(sequences_test, 2)\n",
    "\n",
    "# concatenate along column axis\n",
    "train_all_qs = np.concatenate((train_q1, train_q2), axis=1)\n",
    "test_all_qs = np.concatenate((test_q1, test_q2), axis=1)\n",
    "\n",
    "# turn to dataframe\n",
    "X_train = pd.DataFrame(train_all_qs)\n",
    "X_test = pd.DataFrame(test_all_qs)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove dictionary\n",
    "glove_dictionary = {}\n",
    "with open('glove.6B.200d.txt', encoding=\"utf8\") as file:\n",
    "    for each_line in file:\n",
    "        words, coeffs = each_line.split(maxsplit=1)\n",
    "        coeffs = np.array(coeffs.split(),dtype = float)\n",
    "        glove_dictionary[words] = coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix\n",
    "embedding_matrix = np.zeros((len(vocabulary), 200)) \n",
    "\n",
    "# loop through all vocab words\n",
    "for idx, word in enumerate(vocabulary):\n",
    "    if word in list(glove_dictionary.keys()):\n",
    "        embedding_matrix[idx:] = glove_dictionary[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "with open('glovewordembeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump([X_train, X_test, y_train, y_test, embedding_matrix], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Embeddings - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words approaches (Count, TFIDF, One-hot): hold no information about the meaning of the word, how it is used in language and what is its usual context (i.e. what other words it generally appears close to).\n",
    "\n",
    "Word embeddings: capture the context of the word. Similar words will share similar vector representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word2vec file and extract\n",
    "\n",
    "# !pip install wget\n",
    "# import wget\n",
    "# import gzip\n",
    "\n",
    "# url = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
    "# filename = wget.download(url)\n",
    "\n",
    "# f_in = gzip.open('GoogleNews-vectors-negative300.bin.gz', 'rb')\n",
    "# f_out = open('GoogleNews-vectors-negative300.bin', 'wb')\n",
    "# f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(vocabulary, vector_size=24, epochs=100)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
